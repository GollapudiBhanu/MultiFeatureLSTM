{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_Sample.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PN94TEz3EB7",
        "outputId": "4bca72ad-dfef-45bc-d02b-50b257dc83fc"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjtV_nFI3Hhb"
      },
      "source": [
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from tensorflow.keras import layers, models, backend as K, callbacks\n",
        "from keras.layers import LSTM\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from tensorflow.keras import layers, models, backend as K, callbacks\n",
        "from keras.layers import LSTM\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn import preprocessing\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras import regularizers\n",
        "from keras.layers import TimeDistributed\n",
        "import numpy"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbjy3d6O3PBV",
        "outputId": "55df7023-26fc-426e-c8ca-864baa346cf0"
      },
      "source": [
        "stock_market_df = pd.read_csv('/content/gdrive/MyDrive/Stock_market_label_data.csv')\n",
        "stock_market_df['Match'] = stock_market_df['Match'].replace(['-1'], '0')\n",
        "stock_market_df.drop(columns=['Company_Name', 'Unnamed: 0', 'Date', 'Name'], inplace=True)\n",
        "stock_market_df.fillna(0)\n",
        "stock_market_df = stock_market_df[: 15862]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (86) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1kNXbEN63f3"
      },
      "source": [
        "columns = stock_market_df.columns"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QjfdQLQ3UkN"
      },
      "source": [
        "stock_market_df_1 = stock_market_df.drop(columns=['Match'])\n",
        "X=stock_market_df_1.values"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMt1G0Uf3WSP"
      },
      "source": [
        "norm = MinMaxScaler()\n",
        "X_norm = norm.fit_transform(stock_market_df)\n",
        "X_norm = pd.DataFrame(X_norm, columns = columns)\n",
        "X_norm.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a9RjGrZ7MNw"
      },
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "dataset = scaler.fit_transform(stock_market_df)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qL6m_90S7T6d",
        "outputId": "764d3e5f-a546-4536-9c50-c4426954cef6"
      },
      "source": [
        "train_size = int(len(dataset) * 0.67)\n",
        "test_size = len(dataset) - train_size\n",
        "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "print(len(train), len(test))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10627 5235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WOXIkCX7Zh7"
      },
      "source": [
        "def create_dataset(dataset, look_back=1):\n",
        "\tdataX, dataY = [], []\n",
        "\tfor i in range(len(dataset)-look_back-1):\n",
        "\t\ta = dataset[i:(i+look_back), 0]\n",
        "\t\tdataX.append(a)\n",
        "\t\tdataY.append(dataset[i + look_back, 0])\n",
        "\treturn numpy.array(dataX), numpy.array(dataY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhE5DiGq7hPU"
      },
      "source": [
        "look_back = 1\n",
        "trainX, trainY = create_dataset(train, look_back)\n",
        "testX, testY = create_dataset(test, look_back)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wjd5cp2v7oHc"
      },
      "source": [
        "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
        "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAZ2fAFf7qpk"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(layers.LSTM(4, input_shape=(1, look_back), return_sequences=True))\n",
        "model.add(TimeDistributed(layers.Dense(1, activation='sigmoid')))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics = [tf.keras.metrics.AUC()])\n",
        "\n",
        "\n",
        "#model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sEexcS-J81Oi"
      },
      "source": [
        "checkpoint_filepath = '/content/sample_data/checkpoint'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max')\n",
        "history = model.fit(trainX,trainY,validation_data=(testX, testY),epochs=100, batch_size=1, verbose=2, callbacks=[model_checkpoint_callback])\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}